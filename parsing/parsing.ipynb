{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zq6V3zN4tIo"
      },
      "outputs": [],
      "source": [
        "# Устанавливаем необходимые библиотеки\n",
        "!pip install requests\n",
        "!pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import xml.etree.ElementTree as ET\n",
        "import requests\n",
        "import csv"
      ],
      "metadata": {
        "id": "Uude2E6D5Cys"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cookies_1 = {\n",
        "    'session-cookie': '179de89f534327713e4cb0b280267f93923876c28415fa15a589c53167aa4cb029c12be69cf4abc34cef89b11b6438c4',\n",
        "    'PHPSESSID': 'e0b4742f8c125cbe1b193d6c6d937062',\n",
        "    'sputnik_session': '1701772010701|3',\n",
        "}\n",
        "\n",
        "headers_1 = {\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
        "    'Accept-Language': 'ru,en;q=0.9',\n",
        "    'Cache-Control': 'max-age=0',\n",
        "    'Connection': 'keep-alive',\n",
        "    # 'Cookie': 'session-cookie=179de89f534327713e4cb0b280267f93923876c28415fa15a589c53167aa4cb029c12be69cf4abc34cef89b11b6438c4; PHPSESSID=e0b4742f8c125cbe1b193d6c6d937062; sputnik_session=1701772010701|3',\n",
        "    'Referer': 'http://cikrf.ru/opendata/commitee_list.php',\n",
        "    'Upgrade-Insecure-Requests': '1',\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.2471 YaBrowser/23.11.0.2471 Yowser/2.5 Safari/537.36',\n",
        "}\n",
        "\n",
        "cookies_2 = {\n",
        "    'izbSession': '64b5b4e6-2f81-4b96-8c7e-e074bf77ddc0',\n",
        "    'session-cookie': '179ef5084becc674cb4eb0b280267f9384308ec68e34b70f3eec65bab961a0ae57996adf4a546562c8843651c3afb13c',\n",
        "    'izbFP': 'a289f9847ccd5273811bce9953e2894f',\n",
        "    'JSESSIONID': 'b317e78f92f2a9363fa1963e3817',\n",
        "}\n",
        "\n",
        "headers_2 = {\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
        "    'Accept-Language': 'ru,en;q=0.9',\n",
        "    'Cache-Control': 'max-age=0',\n",
        "    'Connection': 'keep-alive',\n",
        "    'Content-Type': 'application/x-www-form-urlencoded',\n",
        "    # 'Cookie': 'izbSession=64b5b4e6-2f81-4b96-8c7e-e074bf77ddc0; session-cookie=179ef5084becc674cb4eb0b280267f9384308ec68e34b70f3eec65bab961a0ae57996adf4a546562c8843651c3afb13c; izbFP=a289f9847ccd5273811bce9953e2894f; JSESSIONID=b317e78f92f2a9363fa1963e3817',\n",
        "    'Origin': 'http://www.vybory.izbirkom.ru',\n",
        "    'Referer': 'http://www.vybory.izbirkom.ru/region/izbirkom',\n",
        "    'Upgrade-Insecure-Requests': '1',\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.2471 YaBrowser/23.11.0.2471 Yowser/2.5 Safari/537.36',\n",
        "}\n"
      ],
      "metadata": {
        "id": "ti_5hqMzhSgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_data(url, headers, cookies):\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, cookies=cookies, verify=False, timeout=5)\n",
        "        return (response, response.status_code)\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        print(\"Connection refused\")\n",
        "    else:\n",
        "        print(response.status_code)"
      ],
      "metadata": {
        "id": "bGSk4nZd5Cqa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_and_write_from_xml_to_csv(xml_content, csv_filename):\n",
        "    root = ET.fromstring(xml_content)\n",
        "\n",
        "    # Открываем файл CSV для записи\n",
        "    with open(csv_filename, 'w', encoding=\"utf-8\", newline='') as csvfile:\n",
        "\n",
        "        csv_writer = csv.writer(csvfile, delimiter=';')\n",
        "\n",
        "        # Записываем заголовки CSV\n",
        "        headers_of_csv_file = [\"name\"] + [child[0].text for child in root[0]]\n",
        "        csv_writer.writerow(headers_of_csv_file)\n",
        "\n",
        "        # Записываем данные из XML в CSV\n",
        "        for parent in root:\n",
        "            data_row = [parent.attrib[\"name\"]] + [child[1].text if child[1] is not None else '' for child in parent]\n",
        "            csv_writer.writerow(data_row)\n",
        "\n",
        "        print(f\"Данные успешно записаны в {csv_filename}\")"
      ],
      "metadata": {
        "id": "5Raps7u3648S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Следующий парсер написан для сайта vybory.izbirkom.ru, так как сайт cikrf.ru не содержит данные о выборах раньше 2011 года. В таблицах избиркома заголовками являются названия регионов, а первая колонка содержит характеристики типа: \"Число избирателей, внесенных в списки избирателей\" и т.п. Однако это неудобное представление, поэтому пришлось условно транспонировать таблицу, чтобы характеристики были на месте заголовков."
      ],
      "metadata": {
        "id": "JVEFAMbiENgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_and_write_from_html_to_csv(html_content, csv_filename):\n",
        "    soup = BeautifulSoup(html_content, 'lxml')\n",
        "\n",
        "    # Достаём заголовки будущего файла\n",
        "    list_of_head = soup.find('table', id='fix-columns-table').find_all('td', class_='second-fix-col')\n",
        "    native_headers = [list_of_head[i].text for i in range(0, len(list_of_head))]\n",
        "    headers_of_csv_file = [\"name\"] + native_headers\n",
        "\n",
        "    # Достаём \"name\" из изначальной таблицы\n",
        "    soup_f_column = soup.find('table', id='fix-columns-table').find('thead').find_all('a')\n",
        "    first_column = [soup.find('table', id='fix-columns-table').find('thead').find('b').text] + [soup_f_column[i].text for i in range(0, len(soup_f_column))]\n",
        "\n",
        "    # Создаём и заполняем таблицу строчками из изначальной таблицы\n",
        "    data = []\n",
        "    data.append(first_column)\n",
        "\n",
        "    new_soup = soup.find('table', id='fix-columns-table').find('tbody').find_all('tr')\n",
        "\n",
        "    for tr in new_soup:\n",
        "        rows = tr.find_all('b')\n",
        "        if len(rows) != 0:\n",
        "            pr_rows = [rows[i].text if rows[i] is not None else '' for i in range(0, len(rows))]\n",
        "            data.append(pr_rows)\n",
        "\n",
        "    # Открываем файл CSV для записи\n",
        "    with open(csv_filename, 'w', encoding=\"utf-8\", newline='') as csvfile:\n",
        "\n",
        "        csv_writer = csv.writer(csvfile, delimiter=';')\n",
        "\n",
        "        # Записываем заголовки CSV\n",
        "        csv_writer.writerow(headers_of_csv_file)\n",
        "\n",
        "        # Записываем данные из html в CSV\n",
        "        for i in range(0, len(data[0])):\n",
        "            data_row = []\n",
        "            for j in range(0, len(data)):\n",
        "                data_row.append(data[j][i])\n",
        "\n",
        "            csv_writer.writerow(data_row)\n",
        "\n",
        "        print(f\"Данные успешно записаны в {csv_filename}\")"
      ],
      "metadata": {
        "id": "71JSo_2v90LF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот парсер написан специально для сводных результатов выборов президента РФ в 2004 году, так как код таблицы отличается по стилю от кодов остальных таблиц."
      ],
      "metadata": {
        "id": "AjhvZV8JKkvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_2004_elections_and_write_from_html_to_csv(html_content, csv_filename):\n",
        "    soup = BeautifulSoup(html_content, 'lxml')\n",
        "    soup_table = soup.find_all('table', class_='table-bordered')[1]\n",
        "\n",
        "    # Достаём заголовки будущего файла\n",
        "    h_soup = soup_table.find_all('td', class_='text-left')\n",
        "    native_headers = [h_soup[i].find('nobr').text for i in range(0, len(h_soup))]\n",
        "    headers_of_csv_file = [\"name\"] + native_headers\n",
        "\n",
        "    # Достаём строчку с суммарными данными (по всей стране и не только)\n",
        "    sum_row_soup = soup_table.find('td', style='vertical-align: baseline;').find_all('td', class_='text-right')\n",
        "    sum_row = [\"Сумма\"] + [sum_row_soup[i].find('b').text for i in range(0, len(sum_row_soup))]\n",
        "\n",
        "    # Достаём \"name\" из изначальной таблицы\n",
        "    soup_f_column = soup_table.find_all('table', class_='table-bordered')[1].find_all('a')\n",
        "    first_column = [soup_f_column[i].text for i in range(0, len(soup_f_column))]\n",
        "\n",
        "    # Создаём и заполняем таблицу строчками из изначальной таблицы\n",
        "    data = []\n",
        "    data.append(first_column)\n",
        "    table = soup_table.find_all('table', class_='table-striped')[1].find_all('tr')[1:]\n",
        "\n",
        "    for tr in table:\n",
        "        rows = tr.find_all('b')\n",
        "        if len(rows) != 0:\n",
        "            pr_rows = [rows[i].text if rows[i] is not None else '' for i in range(0, len(rows))]\n",
        "            data.append(pr_rows)\n",
        "\n",
        "    # Открываем файл CSV для записи\n",
        "    with open(csv_filename, 'w', encoding=\"utf-8\", newline='') as csvfile:\n",
        "\n",
        "        csv_writer = csv.writer(csvfile, delimiter=';')\n",
        "\n",
        "        # Записываем заголовки CSV\n",
        "        csv_writer.writerow(headers_of_csv_file)\n",
        "\n",
        "        # Записываем строчку с суммарными данными\n",
        "        csv_writer.writerow(sum_row)\n",
        "\n",
        "        # Записываем данные из html в CSV\n",
        "        for i in range(0, len(data[0])):\n",
        "            data_row = []\n",
        "            for j in range(0, len(data)):\n",
        "                data_row.append(data[j][i])\n",
        "\n",
        "            csv_writer.writerow(data_row)\n",
        "\n",
        "        print(f\"Данные успешно записаны в {csv_filename}\")"
      ],
      "metadata": {
        "id": "FbpN2bjxKQJg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ну и наконец создаем списки, которые определяют, в какой файл записываем данные по url-ссылке\n",
        "list_of_ind_filenames = [(7, \"Результаты_выборов_президента_2012\"),\n",
        "                         (15, \"Результаты_выборов_в_думу_2011\"),\n",
        "                         (21, \"Результаты_выборов_в_думу_2016\"),\n",
        "                         (23, \"Результаты_выборов_в_думу_2016_по_фед\"),\n",
        "                         (41, \"Результаты_выборов_президента_2018\"),\n",
        "                         (86, \"Результаты_выборов_в_думу_2021_по_фед\"),\n",
        "                         (87, \"Результаты_выборов_в_думу_2021\")]\n",
        "list_of_url_filenames = [(\"http://www.vybory.izbirkom.ru/region/region/izbirkom?action=show&root=1&tvd=100100095621&vrn=100100095619&region=0&global=1&sub_region=0&prver=0&pronetvd=0&vibid=100100095621&type=233\",\"Результаты_выборов_в_думу_2003_по_фед\"),\n",
        "                         (\"http://www.vybory.izbirkom.ru/region/region/izbirkom?action=show&root=1&tvd=100100021960186&vrn=100100021960181&region=0&global=1&sub_region=0&prver=0&pronetvd=null&vibid=100100021960186&type=233\", \"Результаты_выборов_в_думу_2007_по_фед\"),\n",
        "                         (\"http://www.vybory.izbirkom.ru/region/region/izbirkom?action=show&root=1&tvd=100100022249920&vrn=100100022176412&region=0&global=1&sub_region=0&prver=0&pronetvd=null&vibid=100100022249920&type=227\", \"Результаты_выборов_президента_2008\")]\n",
        "uhhh_2004 = (\"http://www.vybory.izbirkom.ru/region/region/izbirkom?action=show&root=1&tvd=1001000882951&vrn=1001000882950&region=0&global=1&sub_region=0&prver=0&pronetvd=null&vibid=1001000882951&type=227\", \"Результаты_выборов_президента_2004\")\n",
        "\n",
        "for pair in list_of_ind_filenames:\n",
        "    csv_filename = f\"{pair[1]}.csv\"\n",
        "    func_ret = fetch_data(f\"http://www.cikrf.ru/opendata/{pair[0]}.xml\", headers_1, cookies_1)\n",
        "    if func_ret[1] == 200:\n",
        "        parse_and_write_from_xml_to_csv(func_ret[0].content, csv_filename)\n",
        "\n",
        "for pair in list_of_url_filenames:\n",
        "    csv_filename = f\"{pair[1]}.csv\"\n",
        "    func_ret = fetch_data(pair[0], headers_2, cookies_2)\n",
        "    if func_ret[1] == 200:\n",
        "        parse_and_write_from_html_to_csv(func_ret[0].text, csv_filename)\n",
        "\n",
        "\n",
        "csv_filename = f\"{uhhh_2004[1]}.csv\"\n",
        "func_ret = fetch_data(uhhh_2004[0], headers_2, cookies_2)\n",
        "if func_ret == 200:\n",
        "    parse_2004_elections_and_write_from_html_to_csv(func_ret[0].text, csv_filename)"
      ],
      "metadata": {
        "id": "Ug6Lk6e_SvML"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}